{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/DSApps_logo_small.jpg\">\n",
    "\n",
    "# DSApps 2023 @ TAU: Assignment 3\n",
    "\n",
    "### Giora Simchoni\n",
    "\n",
    "### Some Pandas and Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome\n",
    "\n",
    "Welcome to Assignment 3 in Python!\n",
    "\n",
    "Remember:\n",
    "\n",
    "* You can play with the assignment in Playground mode, but:\n",
    "* Only your private Github repository assigned to you by the course admin will be cloned and graded (Submission mode, see instructions [here](https://github.com/DSApps-2023/Class_Slides/blob/main/Apps_of_DS_HW.pdf))\n",
    "* Like any other University assignment, your work should remain private\n",
    "* You need to `git clone` your private Github repository locally as explained [here](https://github.com/DSApps-2023/Class_Slides/blob/main/Apps_of_DS_HW.pdf)\n",
    "* You need to uncomment the starter code inside the chunk, replace the `### YOUR CODE HERE ###`, run the chunk and see that you're getting the expected result\n",
    "* Pay attention to what you're asked to do and the required output\n",
    "* For example, using a *different* function than the one you were specifically asked to use, will decrease your score (unless you amaze me)\n",
    "* Your notebook should run smoothly from start to end if someone presses in the Jupyter toolbar Kernel --> Restart & Run All\n",
    "* When you're done save the entire notebook into a html file, this is the file that would be graded\n",
    "* You can add other files but do not delete any files\n",
    "* Commit your work and push to your private Github repository as explained [here](https://github.com/DSApps-2023/Class_Slides/blob/main/Apps_of_DS_HW.pdf)\n",
    "\n",
    "This assignemtnt is due: 8/5 23:59\n",
    "\n",
    "### Libraries\n",
    "\n",
    "These are the libraries you will need. If you don't have them, you need to uncomment the `!pip install` line and install them first (you can also just copy this command to a terminal and do it there if you don't want all the output printed in this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib numpy scipy pandas beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Pandas\n",
    "\n",
    "###### (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behold the `fifa_wide` DF. There's only so much we can do with it in current form. Make `fifa_wide` into `fifa_long`, a table with 4 columns (say `['Country', 'Continent', 'Year', 'Rank']`) and 15 rows, holding for each country, for each World Cup year, its Rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>2014</th>\n",
       "      <th>2018</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>Europe</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Europe</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>South America</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>South America</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country      Continent  2014  2018  2022\n",
       "0     France         Europe     7     1     2\n",
       "1    Germany         Europe     1    22    17\n",
       "2      Spain         Europe    23    10    13\n",
       "3  Argentina  South America     2    16     1\n",
       "4     Brazil  South America     4     6     7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifa_d = {'Country': ['France', 'Germany', 'Spain', 'Argentina', 'Brazil'],\n",
    "      'Continent': ['Europe', 'Europe', 'Europe', 'South America', 'South America'],\n",
    "      '2014': [7, 1, 23, 2, 4],\n",
    "      '2018': [1, 22, 10, 16, 6],\n",
    "      '2022': [2, 17, 13, 1, 7]}\n",
    "\n",
    "fifa_wide = pd.DataFrame(fifa_d)\n",
    "fifa_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2014</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2014</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>South America</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>South America</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2018</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>South America</td>\n",
       "      <td>2018</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>South America</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>France</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2022</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2022</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>South America</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>South America</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Country      Continent  Year  Rank\n",
       "0      France         Europe  2014     7\n",
       "1     Germany         Europe  2014     1\n",
       "2       Spain         Europe  2014    23\n",
       "3   Argentina  South America  2014     2\n",
       "4      Brazil  South America  2014     4\n",
       "5      France         Europe  2018     1\n",
       "6     Germany         Europe  2018    22\n",
       "7       Spain         Europe  2018    10\n",
       "8   Argentina  South America  2018    16\n",
       "9      Brazil  South America  2018     6\n",
       "10     France         Europe  2022     2\n",
       "11    Germany         Europe  2022    17\n",
       "12      Spain         Europe  2022    13\n",
       "13  Argentina  South America  2022     1\n",
       "14     Brazil  South America  2022     7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifa_long = pd.melt(fifa_wide, id_vars=['Country', 'Continent'] , var_name='Year', value_name='Rank')\n",
    "\n",
    "fifa_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bME6d1ZfbmsI"
   },
   "source": [
    "We have downloaded from [Gapminder data repository](https://www.gapminder.org/data/) the life expectancy data for all countries in the years 1900-1999. \n",
    "\n",
    "* Upload the `life_expectancy_years.csv` file from Moodle, however you want.\n",
    "* Extract from this dataset countries that have data for all years in the range 1900-1999 (i.e. you should discard countires with `Nan` values in years 1900-1999).\n",
    "* You should get 184 countries.\n",
    "* Create for each of these the average age for each decade (1900-1909, 1910-1919,...), resulting with a matrix of 184 countries (rows) times 10 decades averages (the country's name is an extra column, so 11 columns).\n",
    "\n",
    "\n",
    "**Important:** There are many ways to do this manipulation. Looping isn't a sin, but you should know where to use it.\n",
    "\n",
    "**Sanity check:** the maximum value at the 90s (1990-1999) should be about `80.11`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qh4Yxv2LbmsL"
   },
   "outputs": [],
   "source": [
    "df_pop = pd.read_csv('data/life_expectancy_years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>1900-1909</th>\n",
       "      <th>1910-1919</th>\n",
       "      <th>1920-1929</th>\n",
       "      <th>1930-1939</th>\n",
       "      <th>1940-1949</th>\n",
       "      <th>1950-1959</th>\n",
       "      <th>1960-1969</th>\n",
       "      <th>1970-1979</th>\n",
       "      <th>1980-1989</th>\n",
       "      <th>1990-1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>29.70</td>\n",
       "      <td>28.057</td>\n",
       "      <td>30.92</td>\n",
       "      <td>31.54</td>\n",
       "      <td>32.15</td>\n",
       "      <td>35.40</td>\n",
       "      <td>42.62</td>\n",
       "      <td>46.63</td>\n",
       "      <td>44.78</td>\n",
       "      <td>53.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>35.40</td>\n",
       "      <td>33.800</td>\n",
       "      <td>35.40</td>\n",
       "      <td>40.17</td>\n",
       "      <td>44.87</td>\n",
       "      <td>56.97</td>\n",
       "      <td>65.12</td>\n",
       "      <td>69.41</td>\n",
       "      <td>72.34</td>\n",
       "      <td>73.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>29.54</td>\n",
       "      <td>30.690</td>\n",
       "      <td>31.59</td>\n",
       "      <td>34.75</td>\n",
       "      <td>36.91</td>\n",
       "      <td>49.43</td>\n",
       "      <td>55.10</td>\n",
       "      <td>60.04</td>\n",
       "      <td>67.64</td>\n",
       "      <td>72.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>29.35</td>\n",
       "      <td>28.180</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.40</td>\n",
       "      <td>33.30</td>\n",
       "      <td>37.46</td>\n",
       "      <td>43.21</td>\n",
       "      <td>47.11</td>\n",
       "      <td>47.73</td>\n",
       "      <td>49.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>33.80</td>\n",
       "      <td>32.680</td>\n",
       "      <td>36.95</td>\n",
       "      <td>45.35</td>\n",
       "      <td>53.85</td>\n",
       "      <td>60.63</td>\n",
       "      <td>65.22</td>\n",
       "      <td>68.82</td>\n",
       "      <td>72.80</td>\n",
       "      <td>74.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>32.44</td>\n",
       "      <td>32.190</td>\n",
       "      <td>32.68</td>\n",
       "      <td>34.73</td>\n",
       "      <td>46.16</td>\n",
       "      <td>57.38</td>\n",
       "      <td>63.32</td>\n",
       "      <td>67.38</td>\n",
       "      <td>70.88</td>\n",
       "      <td>72.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>31.04</td>\n",
       "      <td>29.650</td>\n",
       "      <td>30.48</td>\n",
       "      <td>31.56</td>\n",
       "      <td>33.42</td>\n",
       "      <td>50.98</td>\n",
       "      <td>55.89</td>\n",
       "      <td>58.77</td>\n",
       "      <td>66.94</td>\n",
       "      <td>70.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>23.55</td>\n",
       "      <td>23.200</td>\n",
       "      <td>23.60</td>\n",
       "      <td>23.70</td>\n",
       "      <td>23.71</td>\n",
       "      <td>27.68</td>\n",
       "      <td>37.12</td>\n",
       "      <td>47.89</td>\n",
       "      <td>55.73</td>\n",
       "      <td>60.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>33.74</td>\n",
       "      <td>31.950</td>\n",
       "      <td>34.38</td>\n",
       "      <td>34.72</td>\n",
       "      <td>36.92</td>\n",
       "      <td>46.56</td>\n",
       "      <td>51.25</td>\n",
       "      <td>55.53</td>\n",
       "      <td>54.52</td>\n",
       "      <td>47.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>34.12</td>\n",
       "      <td>32.540</td>\n",
       "      <td>34.36</td>\n",
       "      <td>34.48</td>\n",
       "      <td>41.05</td>\n",
       "      <td>50.88</td>\n",
       "      <td>54.91</td>\n",
       "      <td>57.39</td>\n",
       "      <td>61.66</td>\n",
       "      <td>53.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 country  1900-1909  1910-1919  1920-1929  1930-1939  \\\n",
       "0            Afghanistan      29.70     28.057      30.92      31.54   \n",
       "1                Albania      35.40     33.800      35.40      40.17   \n",
       "2                Algeria      29.54     30.690      31.59      34.75   \n",
       "4                 Angola      29.35     28.180      30.73      31.40   \n",
       "5    Antigua and Barbuda      33.80     32.680      36.95      45.35   \n",
       "..                   ...        ...        ...        ...        ...   \n",
       "182            Venezuela      32.44     32.190      32.68      34.73   \n",
       "183              Vietnam      31.04     29.650      30.48      31.56   \n",
       "184                Yemen      23.55     23.200      23.60      23.70   \n",
       "185               Zambia      33.74     31.950      34.38      34.72   \n",
       "186             Zimbabwe      34.12     32.540      34.36      34.48   \n",
       "\n",
       "     1940-1949  1950-1959  1960-1969  1970-1979  1980-1989  1990-1999  \n",
       "0        32.15      35.40      42.62      46.63      44.78      53.17  \n",
       "1        44.87      56.97      65.12      69.41      72.34      73.87  \n",
       "2        36.91      49.43      55.10      60.04      67.64      72.87  \n",
       "4        33.30      37.46      43.21      47.11      47.73      49.08  \n",
       "5        53.85      60.63      65.22      68.82      72.80      74.36  \n",
       "..         ...        ...        ...        ...        ...        ...  \n",
       "182      46.16      57.38      63.32      67.38      70.88      72.48  \n",
       "183      33.42      50.98      55.89      58.77      66.94      70.07  \n",
       "184      23.71      27.68      37.12      47.89      55.73      60.65  \n",
       "185      36.92      46.56      51.25      55.53      54.52      47.14  \n",
       "186      41.05      50.88      54.91      57.39      61.66      53.58  \n",
       "\n",
       "[184 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pop1 = df_pop.iloc[:,[0] + list(range(101,201))]\n",
    "df_pop1 = df_pop1.dropna()\n",
    "means = df_pop1.iloc[:, 1:].groupby(df_pop1.columns[1:].to_series().astype(int)//10, axis=1).mean()\n",
    "first_col = df_pop1.iloc[:,0].to_frame()\n",
    "df_pop2 = pd.concat([first_col, means], axis = 1)\n",
    "new_col_names = [\"country\", \"1900-1909\", \"1910-1919\", \"1920-1929\", \"1930-1939\", \"1940-1949\", \"1950-1959\", \"1960-1969\", \"1970-1979\", \"1980-1989\", \"1990-1999\"]\n",
    "df_pop2.columns = new_col_names\n",
    "df_pop2\n",
    "#max(df_pop2.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S14x7ZhV3Oke"
   },
   "source": [
    "**Note**: the following 3 questions are regarding the dataset you just created, not the original raw data from CSV.\n",
    "\n",
    "Which country had the highest life expectancy in the 1970s (1970-1979) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KcHgPtDC3NNv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Greece'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = df_pop2.loc[df_pop2[\"1970-1979\"].idxmax()]\n",
    "row.at[\"country\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mb8TT4h6bmsh"
   },
   "source": [
    "How many countries had at least 1 \"peak\" decade? A peak decade is a decade which had a higher life expectancy compared to both the deacdes before and after it (the 1900s and 1990s cannot be called that here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4P8PA95Lbmsi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_peak(row):\n",
    "    for i in range(2,10):\n",
    "        if row[i-1] < row[i] and row[i] > row[i+1]:\n",
    "            return 1\n",
    "    return 0\n",
    "df_pop2[\"peak result\"] = df_pop2.apply(is_peak, axis = 1)\n",
    "df_pop2[\"peak result\"].value_counts()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vlpum99Xbmsk"
   },
   "source": [
    "In which decade did most countries experience a decrease in life expectancy compared to the previous decade? (see if you can think of a reason) E.g. if you check from 1980s to 1990s about 20% of countries decreased in life expectency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dsVa69HIbmsk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1910-1919\n"
     ]
    }
   ],
   "source": [
    "def how_many_decreased_for_given_decade(col):\n",
    "    res = 0\n",
    "    j = df_pop2.columns.get_loc(col)\n",
    "    for i in range(184):\n",
    "        if df_pop2.iloc[i,j-1] > df_pop2.iloc[i,j]:\n",
    "            res += 1\n",
    "    return res\n",
    "\n",
    "decades_lst = [\"1910-1919\", \"1920-1929\", \"1930-1939\", \"1940-1949\", \"1950-1959\", \"1960-1969\", \"1970-1979\", \"1980-1989\", \"1990-1999\"]\n",
    "lowest_decade = \"\"\n",
    "curr_lowest = 0\n",
    "lst = []\n",
    "for decade in decades_lst:\n",
    "    lst.append(how_many_decreased_for_given_decade(decade))\n",
    "    x = how_many_decreased_for_given_decade(decade)\n",
    "    if x > curr_lowest:\n",
    "        curr_lowest = x\n",
    "        lowest_decade = decade\n",
    "        \n",
    "print(lowest_decade)\n",
    "#lst ---> indeed from 1980s to 1990s about 20% of countries decreased in life expectency (37 / 184)\n",
    "# we think it is most decreased in 1910-1919 because of World War I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping with BeautifulSoup\n",
    "\n",
    "###### (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to [ebay.com](ebay.com) and search for little boys t-shirts. The ebay website, like any modern website, is filled with text, images and links. But if you are using Google Chrome and you right-click on any page and choose \"View page source\" you will see the raw HTML script behind it. The following code was used to download thousands of boys and girls shirts images from ebay, your mission is to fill in the blanks.\n",
    "\n",
    "Run the following piece of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://il.ebay.com/b/Boys-Tops-Shirts-T-Shirts-for-Boys/260966/bn_1642883?rt=nc&LH_ItemCondition=1000&LH_BIN=1&LH_PrefLoc=3&_pgn=1'\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code imports Beautiful Soup, imports the requests library for handling web connections, assigns an ebay search results page address to a variable called `url`, \"requests\" this URL, stores the response in a variable called `r`, makes a `BeautifulSoup` object out of the response's `content`, and assigns it to a variable called `soup`.\n",
    "\n",
    "It is advised to visit the url using your browser, so you will have a visual understanding of what you are doing.\n",
    "\n",
    "Print the raw HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--[if IE 9]><html class=\"ie9\" lang=\"en\"><![endif]-->\n",
      "<!--[if gt IE 9]><!-->\n",
      "<html lang=\"en\">\n",
      " <!--<![endif]-->\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"Shop eBay for great deals on Boys Tops, Shirts &amp; T-Shirts for Boys. You'll find new or used products in Boys Tops, Shirts &amp; T-Shirts for Boys on eBay. Free shipping on selected items.\" name=\"description\"/>\n",
      "  <title>\n",
      "   Boys Tops, Shirts &amp; T-Shirts for Boys | eBay\n",
      "  </title>\n",
      "  <meta content=\"unsafe-url\" name=\"referrer\"/>\n",
      "  <meta content=\"Boys Tops, Shirts &amp; T-Shirts for Boys | eBay\" property=\"og:title\"/>\n",
      "  <link href=\"https://ir.ebaystatic.com\" rel=\"'preconnect'\"/>\n",
      "  <meta content=\"34E98E6F27109BE1A9DCF19658EEEE33\" name=\"msvalidate.01\"/>\n",
      "  <meta content=\"Shop eBay for great deals on Boys Tops, Shirts &amp; T-Shirts for Boys. You'll find new or used products in Boys Tops, Shirts &amp; T-Shirts for Boys on eBay. Free shipping on selected items.\" property=\"og:description\"/>\n",
      "  <meta content=\"ebay-o\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the page's title? Replace `#### your code here ####` to get the title as a simple string, without html tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boys Tops, Shirts & T-Shirts for Boys | eBay\n"
     ]
    }
   ],
   "source": [
    "url_title = soup.title.get_text()\n",
    "print(url_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the all hyperlinks on page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_links is a: <class 'bs4.element.ResultSet'>\n",
      "\n",
      "first 5 elements in all_links:\n",
      "[<link href=\"https://ir.ebaystatic.com\" rel=\"'preconnect'\"/>, <link href=\"https://il.ebay.com/b/Boys-Tops-Shirts-T-Shirts-for-Boys/260966/bn_1642883\" rel=\"canonical\"/>, <link href=\"https://i.ebayimg.com\" rel=\"preconnect\"/>, <link href=\"//i1.ebayimg.com\" rel=\"dns-prefetch\"/>, <link crossorigin=\"\" href=\"//i.ebayimg.com\" rel=\"preconnect\"/>]\n"
     ]
    }
   ],
   "source": [
    "all_links =soup.find_all('link', href=True)\n",
    "print('all_links is a: ' + str(type(all_links)))\n",
    "print()\n",
    "print('first 5 elements in all_links:')\n",
    "print(all_links[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the class type of `all_links`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the all images on page (no credit):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = soup.find_all('img', href =\"\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a `list` of all image titles from the `images` object, **except for the first one**. Print that list.\n",
    "\n",
    "Hint: `alt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tommy Hilfiger Baby / Boys / Youth Cotton Polo Shirt NEW WITH TAG ALL Sizes !', 'Chivas Del Guadalajara Youth Centered Full Zipper S Grade Track Soccer Jacket', 'NWT 100% Authentic VILEBREQUIN 100 % Cotton POLO - BLUE - BOYS - 4 Years', \"Disney Boys' Toy Story Snug Fit Cotton Pajamas Size 4, 6, 8, 10\", 'Boys toddler CHAMPION 2 piece outfit sets shirts shorts all sizes colors', \"Boy's School Uniform Short Sleeve Polo Shirt TAGLESS (Sizes, 4-20) NWT\", 'Boys Dress Shirt Solid Long Sleeve Formal Kids Wedding Party Boy Size 5 -18 New', 'Roblox Boys Short Sleeve T-Shirt Officially Licensed Black Large 14/16', \"Polo Ralph Lauren Kids' Golf Shirts White Stripe S 5\", 'Boys toddler New balance 2 and 3 piece outfit sets shirts tank top shorts', 'Pajama R Us Boys 5 Pack Ribbed Tank Tops Size 2T/3T 4T/5T 4/5 6/8 10/12 14/16 18', \"NEW BOYS LEVI'S GRAPHIC TEE T SHIRT 2 PIECE PACK SET\", 'BNWT Boys YLG Blue UNDER ARMOUR FREEDOM T Shirt (B1)', 'Nike Dri-Fit Short Sleeve Shirt Youth White/Striped New with Defect', 'Diesel Boys Light Heather Gray Fashion Top Size 4 5 6 7 8 10/12 14 16 $30', 'Youth Boys John Deere Logo Emblem T-Shirt (Green) Size 3T long sleeve', \"Boy's Size XL Multi Colored Blue Cloud Wash Tie Dye Short Sleeve T-Shirt\", 'New w Tag Tommy Hilfiger Boy Toddler Navy T-Shirt Top Back to School', 'NIKE AIR JORDAN JUMPMAN Shirt & Shorts 2 Pc Set Navy & Gray Sz M (10-12): NWT ', 'NEW WITH TAGS Vineyard Vines White T-Shirt Size Small 8-10 Boys Girls', \"NEW!! Nike Boy's Pro Training Dri-Fit Loose Fit Shirts Variety in Size #181\", 'Polo Ralph Lauren big kids polo bear polo shirts fall grey', 'Studio 3 Boys Four Pack Assorted Color T-Shirts Size 2T 3T 4T 5T 4 5/6 7', 'Polo Ralph Lauren Boys Blue Polo Bear Football Graphic Short Sleeve T-Shirt', 'Brand NEW - Toddler Boys 2PC T-Shirt And Shorts Set - Choose Size & Color', 'Berlioni Italy Toddlers Kids Boys Long Sleeve Dress Shirt Set With Tie & Hanky', 'Hawaiian Shirts Boys Flower Leaf Beach Aloha Party Camp Holiday Casual', 'Polo Ralph Lauren Boys Blue Multi Stripe Crew-Neck Short Sleeve T-Shirt', 'Polo Ralph Lauren Shirt Boys Youth Large Bear Astronaut Blue TShirt NEW W TAGS ', 'U.S. Polo Assn Boys 5 Pack Tank Tops Size 4T/5T 4/5 10/12 14/16 18/20', 'Studio 3 Boys Four Pack Assorted Color T-Shirts Size 2T 3T 4T 5T 4 5/6 7', \"Pokemon Big Boys Charizard Short Sleeve T-Shirt - Pokemon Gotta Cath 'EM All...\", 'Polo Ralph Lauren big kids cotton mesh big pony short sleeve polo', 'Worlds Greatest BIG BROTHER T Shirt Boys Youth Kids and Adult Tee T Shirt', \"Boy's Dress Shirt & Tie Set Long Sleeve- Many Colors Available\", '2 - New Boys Size 8 Fortnite & Minecraft  T-shirts  - LICENSED -', 'Boys Long Sleeve Dress Shirt Matching Tie & Hanky Toddler Kids Button Up Set', 'Hurley Youth 2-Pack Boys UPF 50+ Tops  Swim Shirt, Blue, White, ', 'Disney Toy Story Boys Buzz Lightyear T-Shirt - Air Brushed Design Toy Story...', 'Mariokart Boys T Shirt 2 Pk Lot Reeses Peanut Butter Cup Tie Dye Size Small 6/7', 'FREEZE Sonic The Hedgehog Boys Short Sleeve T-Shirt - All Over Print Design...', 'Polo Ralph Lauren Boys Navy Basketball Polo Bear Graphic Short Sleeve T-Shirt', 'Hanes Boy Tank 5-Pack EcoSmart Undershirt Underwear Breathable Lightweight XS-XL', 'Vineyard Vines Boys Striped Soft Jersey Short Sleeve Pocket T-Shirt', 'UNDER ARMOUR Boys Heatgear & Assorted Style Graphic Logo T-Shirts; Szs 4-7, NWT', 'NWT Gap Kids Boys Rugby Polo Shirt Logo u pick size', \"All in Motion Boys' Short Sleeve Graphic Tee  T-Shirt In Black Size Large 12/14\", 'Big Boys CHAMPION short sleeve crewneck t shirts all sizes colors']\n"
     ]
    }
   ],
   "source": [
    "image_titles = []\n",
    "for tag in images[1:]:\n",
    "    title = tag.get('alt')\n",
    "    if title :\n",
    "        image_titles.append(title)\n",
    "print(image_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need images JPEG addresses. Some have them as attribute `src`, some as attribute `data-src`. This is one way to combine the two. Make sure you understand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://i.ebayimg.com/thumbs/images/g/xVAAAOSwba1h-sDI/s-l300.jpg',\n",
       " 'https://i.ebayimg.com/thumbs/images/g/fCMAAOSwpxJkEsIe/s-l300.jpg',\n",
       " 'https://i.ebayimg.com/thumbs/images/g/xgYAAOSwRath7eHS/s-l300.jpg',\n",
       " 'https://i.ebayimg.com/thumbs/images/g/1aYAAOSw~ZNjwlYj/s-l300.jpg',\n",
       " 'https://i.ebayimg.com/thumbs/images/g/leIAAOSwmNVip-W6/s-l300.jpg']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_files_src = [img.get('src', None) for img in images[1:]]\n",
    "image_files_datasrc = [img.get('data-src', None) for img in images[1:]]\n",
    "image_files = [src if datasrc is None else datasrc for src, datasrc in zip(image_files_src, image_files_datasrc)]\n",
    "image_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find a shirt's price.\n",
    "\n",
    "Go to the url in your browser and use the code inspection tool (F12) to look interactively at the url source code. Find the element that holds price data. Notice that the price may be nested within a few levels of html tags. you are searching for the \"lowest\" level, the one that holds the price directly.\n",
    "\n",
    "In our case it is a `span` element with a specific class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the specific class for span elements holding the prices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_class =\"s-item__price\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"s-item__price\">ILS 65.34<span class=\"DEFAULT\"> to </span>ILS 90.82</span>, <span class=\"s-item__price\">ILS 131.01</span>, <span class=\"s-item__price\">ILS 182.01</span>, <span class=\"s-item__price\">ILS 81.87</span>, <span class=\"s-item__price\">ILS 29.09<span class=\"DEFAULT\"> to </span>ILS 36.37</span>]\n"
     ]
    }
   ],
   "source": [
    "price_elements = soup.find_all('span', {'class' : price_class})\n",
    "print(price_elements[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From each of these `price_elements` we extract the actual price text with the `get_text` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILS 131.01\n"
     ]
    }
   ],
   "source": [
    "print(price_elements[1].get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice all prices come with the \"ILS\" prefix and then the number. Also you can see some prices come as a range. For this project we decided to simply take the minimum price of the range.\n",
    "\n",
    "To do so we could split this string to its elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.01\n"
     ]
    }
   ],
   "source": [
    "print(float(price_elements[1].get_text().split(' ')[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it in a function and getting all prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_price(price_element):\n",
    "    try:\n",
    "        price = float(price_element.get_text().split(' ')[1])\n",
    "    except:\n",
    "        price = None\n",
    "    return price\n",
    "\n",
    "prices = [parse_price(price_e) for price_e in price_elements]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to actually download the shirts images! The following function accepts an image file address, a shirt title and the file name for the image and attempts to download the image to the current directory with the specified file name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, title, file_name):\n",
    "    try:\n",
    "        response = requests.get(url)    \n",
    "    except:\n",
    "        return '', ''\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    return title, file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the first image from our page, name it 'test.jpg'. Make sure it was downloaded correctly and see what the function returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Tommy Hilfiger Baby / Boys / Youth Cotton Polo Shirt NEW WITH TAG ALL Sizes !',\n",
       " 'test.jpg')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_image(image_files[0], image_titles[0],'test.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now download all of the page's images, using a loop. \n",
    "\n",
    "First, create a folder named 'boys' in the current directory. You can do it right here in this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file boys already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir boys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the blank to correctly create a dictionary called `images_data` which will hold the `title` of the image, its `file_name`, and the shirt's `price`. Then fill in the blank to correctly download the image with a proper file name using the `download_image` function we wrote for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb23e914eb1546f9a25dde8a74aa8222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=48)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "images_data = {'title': {}, 'file_name': {}, \"price\": {}}\n",
    "\n",
    "\n",
    "f = IntProgress(min = 0, max = len(images[1:])) # instantiate a progress bar\n",
    "display(f) # display the bar\n",
    "\n",
    "for i in range(len(images[1:])):\n",
    "    title, file_name = download_image(image_files[i], 'Picture_' + str(i), 'Picture_' + str(i) + \".jpg\")\n",
    "    images_data['title'][i] = title\n",
    "    images_data['file_name'][i] = file_name\n",
    "    images_data['price'][i] = prices[i]\n",
    "    f.value += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that would prove useful later on is having a dataset which summarizes all we have gathered. That's what `images_data` is for. We're going to use `pandas` to make it a `DataFrame` we can easily read and write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>file_name</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Picture_0</td>\n",
       "      <td>Picture_0.jpg</td>\n",
       "      <td>65.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Picture_1</td>\n",
       "      <td>Picture_1.jpg</td>\n",
       "      <td>131.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Picture_2</td>\n",
       "      <td>Picture_2.jpg</td>\n",
       "      <td>182.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Picture_3</td>\n",
       "      <td>Picture_3.jpg</td>\n",
       "      <td>81.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Picture_4</td>\n",
       "      <td>Picture_4.jpg</td>\n",
       "      <td>29.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title      file_name   price\n",
       "0  Picture_0  Picture_0.jpg   65.34\n",
       "1  Picture_1  Picture_1.jpg  131.01\n",
       "2  Picture_2  Picture_2.jpg  182.01\n",
       "3  Picture_3  Picture_3.jpg   81.87\n",
       "4  Picture_4  Picture_4.jpg   29.09"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_data_df = pd.DataFrame(images_data)\n",
    "print(images_data_df.shape)\n",
    "images_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was fun, we got 48 images. But we're looking to get times ~200 than that, and the same amount of shirts images for girls. \n",
    "\n",
    "The following function was run to get all boys shirts images. Complete it exactly as we did, but don't run it, we have the images for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False # change this to actually run\n",
    "\n",
    "if run:\n",
    "    boys_url = 'https://il.ebay.com/b/Boys-Tops-Shirts-T-Shirts-for-Boys/260966/bn_1642883?rt=nc&LH_ItemCondition=1000&LH_BIN=1&LH_PrefLoc=3&_pgn='\n",
    "    max_pages = 400\n",
    "    boys_items_data = {'title': {}, 'file_id': {}, 'price': {}}\n",
    "\n",
    "    f = IntProgress(min = 0, max = max_pages)\n",
    "    display(f)\n",
    "\n",
    "    all_items_counter = 0\n",
    "\n",
    "    for page_num in range(1, max_pages):\n",
    "        url = boys_url + str(page_num)\n",
    "        try:\n",
    "            r = requests.get(url, \"lxml\")\n",
    "        except:\n",
    "            print('Stopped at page: ' + page_num)\n",
    "            break\n",
    "        soup = BeautifulSoup(r.content)\n",
    "        images = soup.find_all('img', href=False)\n",
    "        image_titles = []\n",
    "        for tag in images[1:]:\n",
    "            title = tag.get('alt')\n",
    "            image_titles.append(title)\n",
    "        image_files_src = [img.get('src', None) for img in images[1:]]\n",
    "        image_files_datasrc = [img.get('data-src', None) for img in images[1:]]\n",
    "        image_files = [src if datasrc is None else datasrc for src, datasrc in zip(image_files_src, image_files_datasrc)]\n",
    "        images = images[1:]\n",
    "        price_class = \"s-item__price\"\n",
    "        price_elements = soup.find_all('span', {'class' : price_class})\n",
    "        prices = [parse_price(price_e) for price_e in price_elements]\n",
    "        \n",
    "        try:\n",
    "            assert len(prices) == len(images)\n",
    "        \n",
    "        except:\n",
    "            print('Found unequal number of prices in page_num % d' % page_num)\n",
    "            prices = [None] * len(images)\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            title, file_name = download_image(image_files[i], 'Picture_' + str(i), 'Picture_' + str(i) + \".jpg\")\n",
    "            boys_items_data['title'][all_items_counter + i] = title\n",
    "            boys_items_data['file_id'][all_items_counter + i] = all_items_counter + i\n",
    "            boys_items_data['price'][all_items_counter + i] = prices[i]\n",
    "        all_items_counter += len(images)\n",
    "        f.value += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap up\n",
    "And that's it, you have used some Pandas to wrangle data and some BeautifulSoup to scrape images from the web. Good luck with the rest of the course!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
